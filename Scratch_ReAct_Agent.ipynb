{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMdt4K+D1Ab3nVzAOeot/Ls",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/oyinloluwa20/ReAct_Agents/blob/main/Scratch_ReAct_Agent.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VxXbbB-40axT",
        "outputId": "e3f4074e-d8de-4b8d-d61a-5a303e5724ca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting groq\n",
            "  Downloading groq-0.9.0-py3-none-any.whl (103 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.5/103.5 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from groq) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from groq) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from groq)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from groq) (2.8.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from groq) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from groq) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->groq) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->groq) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->groq) (2024.7.4)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->groq)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->groq)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->groq) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->groq) (2.20.1)\n",
            "Installing collected packages: h11, httpcore, httpx, groq\n",
            "Successfully installed groq-0.9.0 h11-0.14.0 httpcore-1.0.5 httpx-0.27.0\n"
          ]
        }
      ],
      "source": [
        "%pip install groq"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Default\n",
        "import os\n",
        "\n",
        "from groq import Groq\n",
        "os.environ['GROQ_API_KEY'] = 'gsk_j5rdoNfEx7yOagIb7sDwWGdyb3FYwRdXAC1GDnXENFmq1oOMf'"
      ],
      "metadata": {
        "id": "_ExVX-Z803c3"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "client = Groq(\n",
        "    # This is the default and can be omitted\n",
        "    api_key=os.environ.get(\"GROQ_API_KEY\"),\n",
        ")\n",
        "\n",
        "chat_completion = client.chat.completions.create(\n",
        "    messages=[\n",
        "        {\n",
        "            \"role\": \"system\",\n",
        "            \"content\": \"you are a helpful assistant.\"\n",
        "        },\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": \"Explain the importance of fast language models\",\n",
        "        }\n",
        "    ],\n",
        "    model=\"llama-3.1-70b-versatile\",\n",
        ")\n",
        "\n",
        "print(chat_completion.choices[0].message.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0sI6t5vO1nZX",
        "outputId": "b05503cf-7eed-43e6-e49d-032ff930b0e8"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fast language models have become a crucial component of natural language processing (NLP) and artificial intelligence (AI) systems. The importance of fast language models can be summarized in the following points:\n",
            "\n",
            "1. **Real-time Processing**: Fast language models enable real-time processing of vast amounts of text data, which is essential for applications like language translation, sentiment analysis, and chatbots. Quick response times improve user experience and facilitate seamless interactions.\n",
            "2. **Scalability**: As the amount of text data grows exponentially, fast language models allow for efficient processing and analysis of large datasets. This scalability is vital for industries like customer service, where thousands of support queries need to be handled promptly.\n",
            "3. **Low Latency**: Fast language models minimize latency, enabling applications to respond quickly to user input. This is particularly important for applications like virtual assistants, voice-controlled interfaces, and live captioning, where delays can lead to user frustration.\n",
            "4. **Resource Efficiency**: Fast language models can run on lower-end hardware or smaller servers, reducing the need for extensive computational resources. This makes it more feasible to deploy NLP models in resource-constrained environments, such as edge devices or mobile phones.\n",
            "5. **Cost-Effective**: By processing language data quickly, organizations can reduce computational costs and save on resources like server maintenance, energy consumption, and personnel time.\n",
            "6. **Competitive Advantage**: In industries where time is of the essence, fast language models can provide a competitive advantage. For instance, a company with a fast language model-based customer service system can respond to customer queries faster than its competitors, leading to increased customer satisfaction and loyalty.\n",
            "7. **Enabling Emerging Applications**: Fast language models enable emerging applications like voice-activated interfaces, intelligent virtual assistants, and language-based robotics. These applications rely on quick processing and analysis of natural language to provide an efficient and user-friendly experience.\n",
            "8. **Research and Development**: Fast language models accelerate the development of new NLP techniques and models, allowing researchers to iterate and refine their approaches more rapidly.\n",
            "9. **Enhanced Security**: By processing language data quickly, fast language models can help detect and respond to security threats like phishing attacks, spam messages, and other types of cyber threats more efficiently.\n",
            "10. **Improving Human-Computer Interaction**: Fast language models have the potential to revolutionize human-computer interaction, enabling more natural, intuitive, and efficient communication between humans and machines.\n",
            "\n",
            "In summary, fast language models are essential for many NLP applications, as they enable real-time processing, scalability, low latency, resource efficiency, cost-effectiveness, and a competitive advantage. As language models continue to advance, their speed and efficiency will become increasingly critical for various industries and applications.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Agent():\n",
        "  def __init__(self,client,system):\n",
        "    self.client =client\n",
        "    self.system =system\n",
        "    self.messages =[]\n",
        "    if self.system is not None:\n",
        "      self.messages.append({\"role\":\"system\", \"content\":self.system})\n",
        "\n",
        "  def __call__(self, message=\"\"):\n",
        "    if message:\n",
        "      self.messages.append({\"role\":\"user\", \"content\":message})\n",
        "    result = self.execute()\n",
        "    self.messages.append({\"role\":\"assistant\", \"content\":result})\n",
        "    return result\n",
        "\n",
        "  def execute(self):\n",
        "    completion = client.chat.completions.create(\n",
        "    messages= self.messages,\n",
        "    model=\"llama-3.1-70b-versatile\",\n",
        ")\n",
        "\n",
        "print(chat_completion.choices[0].message.content)\n",
        "\n",
        "\n",
        ""
      ],
      "metadata": {
        "id": "jOo87mkC1nV6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "system_prompt=\"\".strip()"
      ],
      "metadata": {
        "id": "nY6RErTx1nSE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate(operation):\n",
        "  return eval(operation)\n",
        "\n",
        "\n",
        "def get_planet_mass(planet)->float:\n",
        "  match planet.lower():\n",
        "    case \"earth\":\n",
        "      return 5.972e24\n",
        "    case \"mars\":\n",
        "      return 6.39e23\n",
        "    case\"jupiter\":\n",
        "      return 1.898e27\n",
        "    case _:\n",
        "      return 0.0"
      ],
      "metadata": {
        "id": "uOKnFxIp1nOi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HjEElq4L1nKb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IgFTH7rw1nHA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aZaIrI751nDd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NvHXU_x31nAG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sa3zmLHy1m8x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HTP_Rivu1m5T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jV1Mnzwv1m11"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NQSn-7qC1mPd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}